{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Loadout: Optimizing Function Calling with LangChain and Amazon Bedrock\n",
    "\n",
    "This notebook demonstrates the **Less-is-More** approach from the paper \"Less is More: Optimizing Function Calling for LLM Execution on Edge Devices\" (arXiv:2411.15399v1).\n",
    "\n",
    "## Key Concept\n",
    "Instead of providing all available tools to an LLM at once, we:\n",
    "1. Ask the LLM to describe what tools it needs (without showing any tools)\n",
    "2. Use semantic similarity to find the most relevant tools\n",
    "3. Only provide those selected tools to the LLM for function calling\n",
    "\n",
    "This reduces confusion, improves accuracy, and decreases execution time and power consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install langchain langchain-aws boto3 sentence-transformers scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AWS Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-east-1'  # Change to your region\n",
    ")\n",
    "\n",
    "# Initialize ChatBedrock with Converse API\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",  # or another model\n",
    "    client=bedrock_runtime,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 2000\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✓ Bedrock client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Example Tools\n",
    "\n",
    "We'll create a diverse set of tools to demonstrate the Less-is-More approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a collection of tools\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather for a specific location.\"\"\"\n",
    "    return f\"Weather in {location}: Sunny, 72°F\"\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for information about a topic.\"\"\"\n",
    "    return f\"Search results for '{query}': Found 10 relevant articles\"\n",
    "\n",
    "@tool\n",
    "def calculate_math(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except:\n",
    "        return \"Error: Invalid expression\"\n",
    "\n",
    "@tool\n",
    "def translate_text(text: str, target_language: str) -> str:\n",
    "    \"\"\"Translate text to a target language.\"\"\"\n",
    "    return f\"Translated '{text}' to {target_language}\"\n",
    "\n",
    "@tool\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\"\n",
    "\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    \"\"\"Get the current stock price for a given symbol.\"\"\"\n",
    "    return f\"Stock price for {symbol}: $150.25\"\n",
    "\n",
    "@tool\n",
    "def create_calendar_event(title: str, date: str, time: str) -> str:\n",
    "    \"\"\"Create a calendar event with title, date, and time.\"\"\"\n",
    "    return f\"Calendar event '{title}' created for {date} at {time}\"\n",
    "\n",
    "@tool\n",
    "def get_news(category: str) -> str:\n",
    "    \"\"\"Get latest news for a specific category (e.g., technology, sports, business).\"\"\"\n",
    "    return f\"Latest {category} news: 5 articles found\"\n",
    "\n",
    "@tool\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    \"\"\"Convert an amount from one currency to another.\"\"\"\n",
    "    return f\"Converted {amount} {from_currency} to {to_currency}: {amount * 1.2}\"\n",
    "\n",
    "@tool\n",
    "def get_directions(origin: str, destination: str) -> str:\n",
    "    \"\"\"Get directions from origin to destination.\"\"\"\n",
    "    return f\"Directions from {origin} to {destination}: 15 miles, 25 minutes\"\n",
    "\n",
    "# Collect all tools\n",
    "ALL_TOOLS = [\n",
    "    get_weather,\n",
    "    search_web,\n",
    "    calculate_math,\n",
    "    translate_text,\n",
    "    send_email,\n",
    "    get_stock_price,\n",
    "    create_calendar_event,\n",
    "    get_news,\n",
    "    convert_currency,\n",
    "    get_directions\n",
    "]\n",
    "\n",
    "print(f\"✓ Defined {len(ALL_TOOLS)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Less-is-More Tool Selection\n",
    "\n",
    "This is the core of the paper's approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LessIsMoreToolSelector:\n",
    "    \"\"\"Implements the Less-is-More approach for dynamic tool selection.\"\"\"\n",
    "    \n",
    "    def __init__(self, all_tools: List[Any], llm: ChatBedrock, top_k: int = 3):\n",
    "        self.all_tools = all_tools\n",
    "        self.llm = llm\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        # Initialize embedding model (MPNet as mentioned in paper)\n",
    "        print(\"Loading embedding model...\")\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        \n",
    "        # Create tool descriptions and embeddings (offline step)\n",
    "        self.tool_descriptions = []\n",
    "        self.tool_embeddings = []\n",
    "        \n",
    "        for tool in all_tools:\n",
    "            desc = f\"{tool.name}: {tool.description}\"\n",
    "            self.tool_descriptions.append(desc)\n",
    "            embedding = self.embedding_model.encode(desc)\n",
    "            self.tool_embeddings.append(embedding)\n",
    "        \n",
    "        self.tool_embeddings = np.array(self.tool_embeddings)\n",
    "        print(f\"✓ Created embeddings for {len(self.all_tools)} tools\")\n",
    "    \n",
    "    def recommend_tools(self, user_query: str) -> List[str]:\n",
    "        \"\"\"Step 1: Ask LLM to describe ideal tools needed (Tool Recommender).\"\"\"\n",
    "        prompt = f\"\"\"Given the following user query, describe what tools or functions would be needed to complete this task.\n",
    "Do NOT try to answer the query. Instead, list 1-3 tool descriptions that would be helpful.\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "Provide your response as a JSON list of tool descriptions. Example format:\n",
    "[\"A tool to get weather information for a location\", \"A tool to search for nearby restaurants\"]\n",
    "\n",
    "Tool descriptions:\"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "        \n",
    "        # Parse LLM response\n",
    "        try:\n",
    "            # Extract JSON from response\n",
    "            content = response.content\n",
    "            if \"```json\" in content:\n",
    "                content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "            elif \"```\" in content:\n",
    "                content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "            \n",
    "            recommended_descriptions = json.loads(content.strip())\n",
    "        except:\n",
    "            # Fallback: use the entire response as a single description\n",
    "            recommended_descriptions = [response.content]\n",
    "        \n",
    "        return recommended_descriptions\n",
    "    \n",
    "    def select_tools(self, user_query: str, recommended_descriptions: List[str]) -> List[Any]:\n",
    "        \"\"\"Step 2: Use similarity search to find actual tools (Tool Controller).\"\"\"\n",
    "        # Embed the recommended tool descriptions\n",
    "        recommended_embeddings = self.embedding_model.encode(recommended_descriptions)\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        similarities = cosine_similarity(recommended_embeddings, self.tool_embeddings)\n",
    "        \n",
    "        # Get top-k most similar tools\n",
    "        max_similarities = similarities.max(axis=0)\n",
    "        top_indices = np.argsort(max_similarities)[-self.top_k:][::-1]\n",
    "        \n",
    "        selected_tools = [self.all_tools[i] for i in top_indices]\n",
    "        \n",
    "        return selected_tools, top_indices\n",
    "    \n",
    "    def execute_less_is_more(self, user_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the full Less-is-More pipeline.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"User Query: {user_query}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Step 1: Tool Recommender\n",
    "        print(\"Step 1: Tool Recommender - Asking LLM what tools it needs...\")\n",
    "        recommended_descriptions = self.recommend_tools(user_query)\n",
    "        print(f\"LLM recommended tool descriptions:\")\n",
    "        for i, desc in enumerate(recommended_descriptions, 1):\n",
    "            print(f\"  {i}. {desc}\")\n",
    "        \n",
    "        # Step 2: Tool Controller\n",
    "        print(f\"\\nStep 2: Tool Controller - Finding {self.top_k} most similar tools...\")\n",
    "        selected_tools, indices = self.select_tools(user_query, recommended_descriptions)\n",
    "        print(f\"Selected tools:\")\n",
    "        for i, tool in enumerate(selected_tools, 1):\n",
    "            print(f\"  {i}. {tool.name}: {tool.description}\")\n",
    "        \n",
    "        return {\n",
    "            \"query\": user_query,\n",
    "            \"recommended_descriptions\": recommended_descriptions,\n",
    "            \"selected_tools\": selected_tools,\n",
    "            \"tool_names\": [t.name for t in selected_tools]\n",
    "        }\n",
    "\n",
    "print(\"✓ LessIsMoreToolSelector class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Tool Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Less-is-More tool selector\n",
    "selector = LessIsMoreToolSelector(\n",
    "    all_tools=ALL_TOOLS,\n",
    "    llm=llm,\n",
    "    top_k=3  # Select top 3 most relevant tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Weather Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = selector.execute_less_is_more(\n",
    "    \"What's the weather like in San Francisco?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Financial Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = selector.execute_less_is_more(\n",
    "    \"I need to check the stock price of AAPL and convert 1000 USD to EUR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Complex Multi-Tool Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = selector.execute_less_is_more(\n",
    "    \"Search for information about AI and then send an email to my colleague about it\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Baseline vs Less-is-More\n",
    "\n",
    "Let's compare the traditional approach (providing all tools) vs Less-is-More."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_approach(user_query: str, all_tools: List[Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Traditional approach: provide ALL tools to the LLM.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"BASELINE: Providing ALL {len(all_tools)} tools to LLM\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    tool_descriptions = \"\\n\".join([\n",
    "        f\"{i+1}. {tool.name}: {tool.description}\" \n",
    "        for i, tool in enumerate(all_tools)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You have access to the following tools:\n",
    "\n",
    "{tool_descriptions}\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "Which tools would you use? List the tool names.\"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(f\"LLM Response:\\n{response.content}\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"num_tools_provided\": len(all_tools),\n",
    "        \"response\": response.content\n",
    "    }\n",
    "\n",
    "# Compare approaches\n",
    "test_query = \"What's the weather in New York?\"\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# COMPARISON TEST\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "baseline_result = baseline_approach(test_query, ALL_TOOLS)\n",
    "less_is_more_result = selector.execute_less_is_more(test_query)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Baseline: Provided {baseline_result['num_tools_provided']} tools\")\n",
    "print(f\"Less-is-More: Provided {len(less_is_more_result['selected_tools'])} tools\")\n",
    "print(f\"Reduction: {(1 - len(less_is_more_result['selected_tools'])/baseline_result['num_tools_provided'])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits Analysis\n",
    "\n",
    "The Less-is-More approach provides:\n",
    "\n",
    "1. **Reduced Confusion**: LLM sees fewer options, making better decisions\n",
    "2. **Faster Execution**: Smaller context window = faster processing\n",
    "3. **Lower Power Consumption**: Less computation required\n",
    "4. **No Fine-tuning Required**: Works with any LLM out-of-the-box\n",
    "5. **Scalable**: Can handle large tool sets efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Implementing Search Levels\n",
    "\n",
    "The paper describes 3 search levels. Let's implement a simple version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class MultiLevelToolSelector(LessIsMoreToolSelector):\n",
    "    \"\"\"Extended version with multiple search levels.\"\"\"\n",
    "    \n",
    "    def __init__(self, all_tools: List[Any], llm: ChatBedrock, top_k: int = 3, n_clusters: int = 3):\n",
    "        super().__init__(all_tools, llm, top_k)\n",
    "        \n",
    "        # Create tool clusters (Search Level 2)\n",
    "        print(f\"Creating {n_clusters} tool clusters...\")\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        self.tool_clusters = self.kmeans.fit_predict(self.tool_embeddings)\n",
    "        \n",
    "        # Group tools by cluster\n",
    "        self.clustered_tools = {}\n",
    "        for i, cluster_id in enumerate(self.tool_clusters):\n",
    "            if cluster_id not in self.clustered_tools:\n",
    "                self.clustered_tools[cluster_id] = []\n",
    "            self.clustered_tools[cluster_id].append(self.all_tools[i])\n",
    "        \n",
    "        print(f\"✓ Created {len(self.clustered_tools)} clusters\")\n",
    "        for cluster_id, tools in self.clustered_tools.items():\n",
    "            print(f\"  Cluster {cluster_id}: {[t.name for t in tools]}\")\n",
    "    \n",
    "    def select_with_level(self, user_query: str, search_level: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Select tools using specified search level.\"\"\"\n",
    "        print(f\"\\nUsing Search Level {search_level}\")\n",
    "        \n",
    "        if search_level == 1:\n",
    "            # Individual tool selection\n",
    "            return self.execute_less_is_more(user_query)\n",
    "        \n",
    "        elif search_level == 2:\n",
    "            # Cluster-based selection\n",
    "            recommended_descriptions = self.recommend_tools(user_query)\n",
    "            recommended_embeddings = self.embedding_model.encode(recommended_descriptions)\n",
    "            \n",
    "            # Find closest cluster\n",
    "            cluster_centers = self.kmeans.cluster_centers_\n",
    "            similarities = cosine_similarity(recommended_embeddings, cluster_centers)\n",
    "            best_cluster = similarities.max(axis=0).argmax()\n",
    "            \n",
    "            selected_tools = self.clustered_tools[best_cluster]\n",
    "            print(f\"Selected cluster {best_cluster} with {len(selected_tools)} tools\")\n",
    "            \n",
    "            return {\n",
    "                \"query\": user_query,\n",
    "                \"search_level\": 2,\n",
    "                \"cluster_id\": int(best_cluster),\n",
    "                \"selected_tools\": selected_tools,\n",
    "                \"tool_names\": [t.name for t in selected_tools]\n",
    "            }\n",
    "        \n",
    "        else:  # Level 3\n",
    "            # Use all tools\n",
    "            print(f\"Using all {len(self.all_tools)} tools\")\n",
    "            return {\n",
    "                \"query\": user_query,\n",
    "                \"search_level\": 3,\n",
    "                \"selected_tools\": self.all_tools,\n",
    "                \"tool_names\": [t.name for t in self.all_tools]\n",
    "            }\n",
    "\n",
    "# Create multi-level selector\n",
    "multi_selector = MultiLevelToolSelector(\n",
    "    all_tools=ALL_TOOLS,\n",
    "    llm=llm,\n",
    "    top_k=3,\n",
    "    n_clusters=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Search Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"I need to check stock prices and convert currency\"\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# TESTING DIFFERENT SEARCH LEVELS\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "# Test each level\n",
    "for level in [1, 2, 3]:\n",
    "    result = multi_selector.select_with_level(test_query, search_level=level)\n",
    "    print(f\"\\nLevel {level} selected {len(result['selected_tools'])} tools: {result['tool_names']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the **Less-is-More** approach for optimizing function calling:\n",
    "\n",
    "- **Tool Recommender**: LLM describes needed tools without seeing any\n",
    "- **Tool Controller**: Semantic similarity finds the most relevant actual tools\n",
    "- **Search Levels**: Different granularities for different query complexities\n",
    "\n",
    "Key benefits:\n",
    "- ✓ No fine-tuning required\n",
    "- ✓ Works with any LLM (we used Amazon Bedrock)\n",
    "- ✓ Reduces tool confusion\n",
    "- ✓ Faster execution\n",
    "- ✓ Lower resource consumption\n",
    "\n",
    "This approach is particularly valuable for edge deployments where computational resources are limited."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
