{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Less-is-More: Optimizing Function Calling with LangChain and Amazon Bedrock\n",
    "\n",
    "This notebook demonstrates the **Less-is-More** approach from the paper \"Less is More: Optimizing Function Calling for LLM Execution on Edge Devices\" (arXiv:2411.15399v1).\n",
    "\n",
    "## Key Concept\n",
    "Instead of providing all available tools to an LLM at once, we:\n",
    "1. Ask the LLM to describe what tools it needs (without showing any tools)\n",
    "2. Use semantic similarity to find the most relevant tools\n",
    "3. Only provide those selected tools to the LLM for function calling\n",
    "\n",
    "This reduces confusion, improves accuracy, and decreases execution time and power consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://plugin.us-east-1.prod.workshops.aws\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-aws in ./.venv/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: boto3 in ./.venv/lib/python3.11/site-packages (1.41.5)\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.11/site-packages (5.1.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from langchain) (1.1.0)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in ./.venv/lib/python3.11/site-packages (from langchain) (1.0.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.11/site-packages (from langchain) (2.12.5)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in ./.venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (0.4.49)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in ./.venv/lib/python3.11/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in ./.venv/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in ./.venv/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.11/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in ./.venv/lib/python3.11/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.11/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./.venv/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.11/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.42.0,>=1.41.5 in ./.venv/lib/python3.11/site-packages (from boto3) (1.41.5)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.venv/lib/python3.11/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.16.0,>=0.15.0 in ./.venv/lib/python3.11/site-packages (from boto3) (0.15.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.venv/lib/python3.11/site-packages (from botocore<1.42.0,>=1.41.5->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in ./.venv/lib/python3.11/site-packages (from botocore<1.42.0,>=1.41.5->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.42.0,>=1.41.5->boto3) (1.17.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain) (3.4.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langchain-aws boto3 sentence-transformers scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hochabya/projects/context-engineering-series/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure AWS Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Bedrock client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-east-1'  # Change to your region\n",
    ")\n",
    "\n",
    "# Initialize ChatBedrock with Converse API\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",  # or another model\n",
    "    client=bedrock_runtime,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 2000\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"✓ Bedrock client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Example Tools\n",
    "\n",
    "We'll create a diverse set of tools to demonstrate the Less-is-More approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Defined 10 tools\n"
     ]
    }
   ],
   "source": [
    "# Define a collection of tools\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get the current weather for a specific location.\"\"\"\n",
    "    return f\"Weather in {location}: Sunny, 72°F\"\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for information about a topic.\"\"\"\n",
    "    return f\"Search results for '{query}': Found 10 relevant articles\"\n",
    "\n",
    "@tool\n",
    "def calculate_math(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"Result: {result}\"\n",
    "    except:\n",
    "        return \"Error: Invalid expression\"\n",
    "\n",
    "@tool\n",
    "def translate_text(text: str, target_language: str) -> str:\n",
    "    \"\"\"Translate text to a target language.\"\"\"\n",
    "    return f\"Translated '{text}' to {target_language}\"\n",
    "\n",
    "@tool\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\"\n",
    "\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    \"\"\"Get the current stock price for a given symbol.\"\"\"\n",
    "    return f\"Stock price for {symbol}: $150.25\"\n",
    "\n",
    "@tool\n",
    "def create_calendar_event(title: str, date: str, time: str) -> str:\n",
    "    \"\"\"Create a calendar event with title, date, and time.\"\"\"\n",
    "    return f\"Calendar event '{title}' created for {date} at {time}\"\n",
    "\n",
    "@tool\n",
    "def get_news(category: str) -> str:\n",
    "    \"\"\"Get latest news for a specific category (e.g., technology, sports, business).\"\"\"\n",
    "    return f\"Latest {category} news: 5 articles found\"\n",
    "\n",
    "@tool\n",
    "def convert_currency(amount: float, from_currency: str, to_currency: str) -> str:\n",
    "    \"\"\"Convert an amount from one currency to another.\"\"\"\n",
    "    return f\"Converted {amount} {from_currency} to {to_currency}: {amount * 1.2}\"\n",
    "\n",
    "@tool\n",
    "def get_directions(origin: str, destination: str) -> str:\n",
    "    \"\"\"Get directions from origin to destination.\"\"\"\n",
    "    return f\"Directions from {origin} to {destination}: 15 miles, 25 minutes\"\n",
    "\n",
    "# Collect all tools\n",
    "ALL_TOOLS = [\n",
    "    get_weather,\n",
    "    search_web,\n",
    "    calculate_math,\n",
    "    translate_text,\n",
    "    send_email,\n",
    "    get_stock_price,\n",
    "    create_calendar_event,\n",
    "    get_news,\n",
    "    convert_currency,\n",
    "    get_directions\n",
    "]\n",
    "\n",
    "print(f\"✓ Defined {len(ALL_TOOLS)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Less-is-More Tool Selection\n",
    "\n",
    "This is the core of the paper's approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LessIsMoreToolSelector class defined\n"
     ]
    }
   ],
   "source": [
    "class LessIsMoreToolSelector:\n",
    "    \"\"\"Implements the Less-is-More approach for dynamic tool selection.\"\"\"\n",
    "    \n",
    "    def __init__(self, all_tools: List[Any], llm: ChatBedrock, top_k: int = 3):\n",
    "        self.all_tools = all_tools\n",
    "        self.llm = llm\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        # Initialize embedding model (MPNet as mentioned in paper)\n",
    "        print(\"Loading embedding model...\")\n",
    "        self.embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "        \n",
    "        # Create tool descriptions and embeddings (offline step)\n",
    "        self.tool_descriptions = []\n",
    "        self.tool_embeddings = []\n",
    "        \n",
    "        for tool in all_tools:\n",
    "            desc = f\"{tool.name}: {tool.description}\"\n",
    "            self.tool_descriptions.append(desc)\n",
    "            embedding = self.embedding_model.encode(desc)\n",
    "            self.tool_embeddings.append(embedding)\n",
    "        \n",
    "        self.tool_embeddings = np.array(self.tool_embeddings)\n",
    "        print(f\"✓ Created embeddings for {len(self.all_tools)} tools\")\n",
    "    \n",
    "    def recommend_tools(self, user_query: str) -> List[str]:\n",
    "        \"\"\"Step 1: Ask LLM to describe ideal tools needed (Tool Recommender).\"\"\"\n",
    "        prompt = f\"\"\"Given the following user query, describe what tools or functions would be needed to complete this task.\n",
    "Do NOT try to answer the query. Instead, list 1-3 tool descriptions that would be helpful.\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "Provide your response as a JSON list of tool descriptions. Example format:\n",
    "[\"A tool to get weather information for a location\", \"A tool to search for nearby restaurants\"]\n",
    "\n",
    "Tool descriptions:\"\"\"\n",
    "        \n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        response = self.llm.invoke(messages)\n",
    "        \n",
    "        # Parse LLM response\n",
    "        try:\n",
    "            # Extract JSON from response\n",
    "            content = response.content\n",
    "            if \"```json\" in content:\n",
    "                content = content.split(\"```json\")[1].split(\"```\")[0]\n",
    "            elif \"```\" in content:\n",
    "                content = content.split(\"```\")[1].split(\"```\")[0]\n",
    "            \n",
    "            recommended_descriptions = json.loads(content.strip())\n",
    "        except:\n",
    "            # Fallback: use the entire response as a single description\n",
    "            recommended_descriptions = [response.content]\n",
    "        \n",
    "        return recommended_descriptions\n",
    "    \n",
    "    def select_tools(self, user_query: str, recommended_descriptions: List[str]) -> List[Any]:\n",
    "        \"\"\"Step 2: Use similarity search to find actual tools (Tool Controller).\"\"\"\n",
    "        # Embed the recommended tool descriptions\n",
    "        recommended_embeddings = self.embedding_model.encode(recommended_descriptions)\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        similarities = cosine_similarity(recommended_embeddings, self.tool_embeddings)\n",
    "        \n",
    "        # Get top-k most similar tools\n",
    "        max_similarities = similarities.max(axis=0)\n",
    "        top_indices = np.argsort(max_similarities)[-self.top_k:][::-1]\n",
    "        \n",
    "        selected_tools = [self.all_tools[i] for i in top_indices]\n",
    "        \n",
    "        return selected_tools, top_indices\n",
    "    \n",
    "    def execute_less_is_more(self, user_query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the full Less-is-More pipeline.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"User Query: {user_query}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Step 1: Tool Recommender\n",
    "        print(\"Step 1: Tool Recommender - Asking LLM what tools it needs...\")\n",
    "        recommended_descriptions = self.recommend_tools(user_query)\n",
    "        print(f\"LLM recommended tool descriptions:\")\n",
    "        for i, desc in enumerate(recommended_descriptions, 1):\n",
    "            print(f\"  {i}. {desc}\")\n",
    "        \n",
    "        # Step 2: Tool Controller\n",
    "        print(f\"\\nStep 2: Tool Controller - Finding {self.top_k} most similar tools...\")\n",
    "        selected_tools, indices = self.select_tools(user_query, recommended_descriptions)\n",
    "        print(f\"Selected tools:\")\n",
    "        for i, tool in enumerate(selected_tools, 1):\n",
    "            print(f\"  {i}. {tool.name}: {tool.description}\")\n",
    "        \n",
    "        return {\n",
    "            \"query\": user_query,\n",
    "            \"recommended_descriptions\": recommended_descriptions,\n",
    "            \"selected_tools\": selected_tools,\n",
    "            \"tool_names\": [t.name for t in selected_tools]\n",
    "        }\n",
    "\n",
    "print(\"✓ LessIsMoreToolSelector class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Tool Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "✓ Created embeddings for 10 tools\n"
     ]
    }
   ],
   "source": [
    "# Create the Less-is-More tool selector\n",
    "selector = LessIsMoreToolSelector(\n",
    "    all_tools=ALL_TOOLS,\n",
    "    llm=llm,\n",
    "    top_k=3  # Select top 3 most relevant tools\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Weather Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: What's the weather like in San Francisco?\n",
      "============================================================\n",
      "\n",
      "Step 1: Tool Recommender - Asking LLM what tools it needs...\n",
      "LLM recommended tool descriptions:\n",
      "  1. A tool to get current weather information for a specific city or location\n",
      "\n",
      "Step 2: Tool Controller - Finding 3 most similar tools...\n",
      "Selected tools:\n",
      "  1. get_weather: Get the current weather for a specific location.\n",
      "  2. get_news: Get latest news for a specific category (e.g., technology, sports, business).\n",
      "  3. search_web: Search the web for information about a topic.\n"
     ]
    }
   ],
   "source": [
    "result1 = selector.execute_less_is_more(\n",
    "    \"What's the weather like in San Francisco?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Financial Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: I need to check the stock price of AAPL and convert 1000 USD to EUR\n",
      "============================================================\n",
      "\n",
      "Step 1: Tool Recommender - Asking LLM what tools it needs...\n",
      "LLM recommended tool descriptions:\n",
      "  1. A tool to get current stock prices for publicly traded companies using their ticker symbols\n",
      "  2. A tool to convert currency amounts between different currencies using current exchange rates\n",
      "\n",
      "Step 2: Tool Controller - Finding 3 most similar tools...\n",
      "Selected tools:\n",
      "  1. get_stock_price: Get the current stock price for a given symbol.\n",
      "  2. convert_currency: Convert an amount from one currency to another.\n",
      "  3. translate_text: Translate text to a target language.\n"
     ]
    }
   ],
   "source": [
    "result2 = selector.execute_less_is_more(\n",
    "    \"I need to check the stock price of AAPL and convert 1000 USD to EUR\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Complex Multi-Tool Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Query: Search for information about AI and then send an email to my colleague about it\n",
      "============================================================\n",
      "\n",
      "Step 1: Tool Recommender - Asking LLM what tools it needs...\n",
      "LLM recommended tool descriptions:\n",
      "  1. A tool to search the internet for information about AI topics and research\n",
      "  2. A tool to compose and send emails to specified recipients\n",
      "\n",
      "Step 2: Tool Controller - Finding 3 most similar tools...\n",
      "Selected tools:\n",
      "  1. send_email: Send an email to a recipient.\n",
      "  2. search_web: Search the web for information about a topic.\n",
      "  3. get_news: Get latest news for a specific category (e.g., technology, sports, business).\n"
     ]
    }
   ],
   "source": [
    "result3 = selector.execute_less_is_more(\n",
    "    \"Search for information about AI and then send an email to my colleague about it\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Baseline vs Less-is-More\n",
    "\n",
    "Let's compare the traditional approach (providing all tools) vs Less-is-More."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "# COMPARISON TEST\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "BASELINE: Providing ALL 10 tools to LLM\n",
      "============================================================\n",
      "\n",
      "LLM Response:\n",
      "I would use the following tool:\n",
      "\n",
      "**get_weather**\n",
      "\n",
      "This tool is specifically designed to get the current weather for a specific location, which directly matches the user's request for weather information in New York.\n",
      "\n",
      "============================================================\n",
      "User Query: What's the weather in New York?\n",
      "============================================================\n",
      "\n",
      "Step 1: Tool Recommender - Asking LLM what tools it needs...\n",
      "LLM recommended tool descriptions:\n",
      "  1. A tool to get current weather information for a specific city or location\n",
      "\n",
      "Step 2: Tool Controller - Finding 3 most similar tools...\n",
      "Selected tools:\n",
      "  1. get_weather: Get the current weather for a specific location.\n",
      "  2. get_news: Get latest news for a specific category (e.g., technology, sports, business).\n",
      "  3. search_web: Search the web for information about a topic.\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Baseline: Provided 10 tools\n",
      "Less-is-More: Provided 3 tools\n",
      "Reduction: 70.0%\n"
     ]
    }
   ],
   "source": [
    "def baseline_approach(user_query: str, all_tools: List[Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Traditional approach: provide ALL tools to the LLM.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"BASELINE: Providing ALL {len(all_tools)} tools to LLM\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    tool_descriptions = \"\\n\".join([\n",
    "        f\"{i+1}. {tool.name}: {tool.description}\" \n",
    "        for i, tool in enumerate(all_tools)\n",
    "    ])\n",
    "    \n",
    "    prompt = f\"\"\"You have access to the following tools:\n",
    "\n",
    "{tool_descriptions}\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "Which tools would you use? List the tool names.\"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    print(f\"LLM Response:\\n{response.content}\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": user_query,\n",
    "        \"num_tools_provided\": len(all_tools),\n",
    "        \"response\": response.content\n",
    "    }\n",
    "\n",
    "# Compare approaches\n",
    "test_query = \"What's the weather in New York?\"\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# COMPARISON TEST\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "baseline_result = baseline_approach(test_query, ALL_TOOLS)\n",
    "less_is_more_result = selector.execute_less_is_more(test_query)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Baseline: Provided {baseline_result['num_tools_provided']} tools\")\n",
    "print(f\"Less-is-More: Provided {len(less_is_more_result['selected_tools'])} tools\")\n",
    "print(f\"Reduction: {(1 - len(less_is_more_result['selected_tools'])/baseline_result['num_tools_provided'])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits Analysis\n",
    "\n",
    "The Less-is-More approach provides:\n",
    "\n",
    "1. **Reduced Confusion**: LLM sees fewer options, making better decisions\n",
    "2. **Faster Execution**: Smaller context window = faster processing\n",
    "3. **Lower Power Consumption**: Less computation required\n",
    "4. **No Fine-tuning Required**: Works with any LLM out-of-the-box\n",
    "5. **Scalable**: Can handle large tool sets efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Implementing Search Levels\n",
    "\n",
    "The paper describes 3 search levels. Let's implement a simple version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n",
      "✓ Created embeddings for 10 tools\n",
      "Creating 3 tool clusters...\n",
      "✓ Created 3 clusters\n",
      "  Cluster 2: ['get_weather', 'calculate_math', 'get_stock_price', 'create_calendar_event', 'get_directions']\n",
      "  Cluster 1: ['search_web', 'get_news']\n",
      "  Cluster 0: ['translate_text', 'send_email', 'convert_currency']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class MultiLevelToolSelector(LessIsMoreToolSelector):\n",
    "    \"\"\"Extended version with multiple search levels.\"\"\"\n",
    "    \n",
    "    def __init__(self, all_tools: List[Any], llm: ChatBedrock, top_k: int = 3, n_clusters: int = 3):\n",
    "        super().__init__(all_tools, llm, top_k)\n",
    "        \n",
    "        # Create tool clusters (Search Level 2)\n",
    "        print(f\"Creating {n_clusters} tool clusters...\")\n",
    "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        self.tool_clusters = self.kmeans.fit_predict(self.tool_embeddings)\n",
    "        \n",
    "        # Group tools by cluster\n",
    "        self.clustered_tools = {}\n",
    "        for i, cluster_id in enumerate(self.tool_clusters):\n",
    "            if cluster_id not in self.clustered_tools:\n",
    "                self.clustered_tools[cluster_id] = []\n",
    "            self.clustered_tools[cluster_id].append(self.all_tools[i])\n",
    "        \n",
    "        print(f\"✓ Created {len(self.clustered_tools)} clusters\")\n",
    "        for cluster_id, tools in self.clustered_tools.items():\n",
    "            print(f\"  Cluster {cluster_id}: {[t.name for t in tools]}\")\n",
    "    \n",
    "    def select_with_level(self, user_query: str, search_level: int = 1) -> Dict[str, Any]:\n",
    "        \"\"\"Select tools using specified search level.\"\"\"\n",
    "        print(f\"\\nUsing Search Level {search_level}\")\n",
    "        \n",
    "        if search_level == 1:\n",
    "            # Individual tool selection\n",
    "            return self.execute_less_is_more(user_query)\n",
    "        \n",
    "        elif search_level == 2:\n",
    "            # Cluster-based selection\n",
    "            recommended_descriptions = self.recommend_tools(user_query)\n",
    "            recommended_embeddings = self.embedding_model.encode(recommended_descriptions)\n",
    "            \n",
    "            # Find closest cluster\n",
    "            cluster_centers = self.kmeans.cluster_centers_\n",
    "            similarities = cosine_similarity(recommended_embeddings, cluster_centers)\n",
    "            best_cluster = similarities.max(axis=0).argmax()\n",
    "            \n",
    "            selected_tools = self.clustered_tools[best_cluster]\n",
    "            print(f\"Selected cluster {best_cluster} with {len(selected_tools)} tools\")\n",
    "            \n",
    "            return {\n",
    "                \"query\": user_query,\n",
    "                \"search_level\": 2,\n",
    "                \"cluster_id\": int(best_cluster),\n",
    "                \"selected_tools\": selected_tools,\n",
    "                \"tool_names\": [t.name for t in selected_tools]\n",
    "            }\n",
    "        \n",
    "        else:  # Level 3\n",
    "            # Use all tools\n",
    "            print(f\"Using all {len(self.all_tools)} tools\")\n",
    "            return {\n",
    "                \"query\": user_query,\n",
    "                \"search_level\": 3,\n",
    "                \"selected_tools\": self.all_tools,\n",
    "                \"tool_names\": [t.name for t in self.all_tools]\n",
    "            }\n",
    "\n",
    "# Create multi-level selector\n",
    "multi_selector = MultiLevelToolSelector(\n",
    "    all_tools=ALL_TOOLS,\n",
    "    llm=llm,\n",
    "    top_k=3,\n",
    "    n_clusters=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Different Search Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "# TESTING DIFFERENT SEARCH LEVELS\n",
      "############################################################\n",
      "\n",
      "Using Search Level 1\n",
      "\n",
      "============================================================\n",
      "User Query: I need to check stock prices and convert currency\n",
      "============================================================\n",
      "\n",
      "Step 1: Tool Recommender - Asking LLM what tools it needs...\n",
      "LLM recommended tool descriptions:\n",
      "  1. A tool to retrieve current and historical stock prices for specific ticker symbols\n",
      "  2. A tool to convert between different currencies using current exchange rates\n",
      "\n",
      "Step 2: Tool Controller - Finding 3 most similar tools...\n",
      "Selected tools:\n",
      "  1. get_stock_price: Get the current stock price for a given symbol.\n",
      "  2. convert_currency: Convert an amount from one currency to another.\n",
      "  3. translate_text: Translate text to a target language.\n",
      "\n",
      "Level 1 selected 3 tools: ['get_stock_price', 'convert_currency', 'translate_text']\n",
      "------------------------------------------------------------\n",
      "\n",
      "Using Search Level 2\n",
      "Selected cluster 2 with 5 tools\n",
      "\n",
      "Level 2 selected 5 tools: ['get_weather', 'calculate_math', 'get_stock_price', 'create_calendar_event', 'get_directions']\n",
      "------------------------------------------------------------\n",
      "\n",
      "Using Search Level 3\n",
      "Using all 10 tools\n",
      "\n",
      "Level 3 selected 10 tools: ['get_weather', 'search_web', 'calculate_math', 'translate_text', 'send_email', 'get_stock_price', 'create_calendar_event', 'get_news', 'convert_currency', 'get_directions']\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_query = \"I need to check stock prices and convert currency\"\n",
    "\n",
    "print(\"\\n\" + \"#\"*60)\n",
    "print(\"# TESTING DIFFERENT SEARCH LEVELS\")\n",
    "print(\"#\"*60)\n",
    "\n",
    "# Test each level\n",
    "for level in [1, 2, 3]:\n",
    "    result = multi_selector.select_with_level(test_query, search_level=level)\n",
    "    print(f\"\\nLevel {level} selected {len(result['selected_tools'])} tools: {result['tool_names']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the **Less-is-More** approach for optimizing function calling:\n",
    "\n",
    "- **Tool Recommender**: LLM describes needed tools without seeing any\n",
    "- **Tool Controller**: Semantic similarity finds the most relevant actual tools\n",
    "- **Search Levels**: Different granularities for different query complexities\n",
    "\n",
    "Key benefits:\n",
    "- ✓ No fine-tuning required\n",
    "- ✓ Works with any LLM (we used Amazon Bedrock)\n",
    "- ✓ Reduces tool confusion\n",
    "- ✓ Faster execution\n",
    "- ✓ Lower resource consumption\n",
    "\n",
    "This approach is particularly valuable for edge deployments where computational resources are limited."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
