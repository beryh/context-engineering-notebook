{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Summarization with Amazon Bedrock\n",
    "\n",
    "**Context Summarization** = Boiling down an accrued context into a condensed summary to prevent context distraction.\n",
    "\n",
    "## Why Summarize Context?\n",
    "\n",
    "1. **Context Distraction**: Beyond ~100k tokens, models favor repeating past actions over novel synthesis\n",
    "2. **Cost & Latency**: Smaller contexts = faster responses and lower costs\n",
    "3. **Focus**: Preserves what matters, removes noise\n",
    "\n",
    "**Reference**: [How to Fix Your Context](https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html#context-summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "MODEL_ID = \"us.anthropic.claude-sonnet-4-20250514-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Summarization Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text: str, focus: str = None, max_tokens: int = 500) -> str:\n",
    "    \"\"\"Summarize text with optional focus area.\"\"\"\n",
    "    focus_instruction = f\" Focus on: {focus}\" if focus else \"\"\n",
    "    \n",
    "    response = bedrock.converse(\n",
    "        modelId=MODEL_ID,\n",
    "        messages=[{\"role\": \"user\", \"content\": [{\"text\": \n",
    "            f\"Summarize this concisely, preserving key facts and decisions.{focus_instruction}\\n\\n{text}\"\n",
    "        }]}],\n",
    "        inferenceConfig={\"temperature\": 0.3, \"maxTokens\": max_tokens}\n",
    "    )\n",
    "    return response['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conversation Summarizer\n",
    "\n",
    "Summarize conversation history when it grows too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConversationSummarizer:\n",
    "    \"\"\"Manages conversation with automatic summarization.\"\"\"\n",
    "    \n",
    "    def __init__(self, system_prompt: str, max_messages: int = 10):\n",
    "        self.system_prompt = system_prompt\n",
    "        self.max_messages = max_messages\n",
    "        self.messages = []\n",
    "        self.summary = None\n",
    "        \n",
    "    def _summarize_history(self) -> str:\n",
    "        \"\"\"Create summary of conversation history.\"\"\"\n",
    "        history = \"\\n\".join([\n",
    "            f\"{m['role'].upper()}: {m['content'][0]['text'][:200]}...\" \n",
    "            for m in self.messages\n",
    "        ])\n",
    "        \n",
    "        response = bedrock.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"text\": \n",
    "                f\"Summarize this conversation, preserving: key decisions, facts, user preferences, and current task state.\\n\\n{history}\"\n",
    "            }]}],\n",
    "            inferenceConfig={\"temperature\": 0.3, \"maxTokens\": 400}\n",
    "        )\n",
    "        return response['output']['message']['content'][0]['text']\n",
    "    \n",
    "    def _maybe_compress(self):\n",
    "        \"\"\"Compress if messages exceed threshold.\"\"\"\n",
    "        if len(self.messages) >= self.max_messages:\n",
    "            self.summary = self._summarize_history()\n",
    "            # Keep only last 2 exchanges\n",
    "            self.messages = self.messages[-4:]\n",
    "            print(f\"üì¶ Compressed! Summary: {self.summary[:100]}...\")\n",
    "    \n",
    "    def chat(self, user_input: str) -> str:\n",
    "        \"\"\"Send message and get response.\"\"\"\n",
    "        self._maybe_compress()\n",
    "        \n",
    "        # Build system with summary if exists\n",
    "        system = self.system_prompt\n",
    "        if self.summary:\n",
    "            system += f\"\\n\\nPrevious conversation summary:\\n{self.summary}\"\n",
    "        \n",
    "        self.messages.append({\"role\": \"user\", \"content\": [{\"text\": user_input}]})\n",
    "        \n",
    "        response = bedrock.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=self.messages,\n",
    "            system=[{\"text\": system}],\n",
    "            inferenceConfig={\"temperature\": 0.7, \"maxTokens\": 1000}\n",
    "        )\n",
    "        \n",
    "        answer = response['output']['message']['content'][0]['text']\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": [{\"text\": answer}]})\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def stats(self):\n",
    "        return {\"messages\": len(self.messages), \"has_summary\": self.summary is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ What's the best way to handle errors in Python?\n",
      "ü§ñ Here are the best practices for handling errors in Python:\n",
      "\n",
      "## 1. Use Try-Except Blocks\n",
      "\n",
      "```python\n",
      "try:\n",
      "    # Code that might raise an exception\n",
      "    r...\n",
      "   Stats: {'messages': 2, 'has_summary': False}\n",
      "\n",
      "üë§ Can you show me a try-except example?\n",
      "ü§ñ Here are several try-except examples from simple to more complex:\n",
      "\n",
      "## Basic Try-Except\n",
      "\n",
      "```python\n",
      "try:\n",
      "    number = int(input(\"Enter a number: \"))\n",
      "   ...\n",
      "   Stats: {'messages': 4, 'has_summary': False}\n",
      "\n",
      "üë§ What about custom exceptions?\n",
      "ü§ñ Here's a comprehensive guide to creating and using custom exceptions in Python:\n",
      "\n",
      "## 1. Basic Custom Exception\n",
      "\n",
      "```python\n",
      "class CustomError(Exception):...\n",
      "   Stats: {'messages': 6, 'has_summary': False}\n",
      "\n",
      "üë§ How do I log errors properly?\n",
      "üì¶ Compressed! Summary: ## Conversation Summary\n",
      "\n",
      "**Topic**: Python error handling best practices\n",
      "\n",
      "**Key Decisions/Recommenda...\n",
      "ü§ñ Here's a comprehensive guide to logging errors properly in Python:\n",
      "\n",
      "## 1. Basic Error Logging Setup\n",
      "\n",
      "```python\n",
      "import logging\n",
      "\n",
      "# Configure logging\n",
      "log...\n",
      "   Stats: {'messages': 6, 'has_summary': True}\n",
      "\n",
      "üë§ What logging levels should I use?\n",
      "üì¶ Compressed! Summary: ## Conversation Summary\n",
      "\n",
      "**Key Topic:** Python error handling and logging\n",
      "\n",
      "**Key Decisions/Preferenc...\n",
      "ü§ñ Here's a comprehensive guide to Python logging levels and when to use each one:\n",
      "\n",
      "## 1. Understanding Logging Levels\n",
      "\n",
      "```python\n",
      "import logging\n",
      "\n",
      "# Set u...\n",
      "   Stats: {'messages': 6, 'has_summary': True}\n"
     ]
    }
   ],
   "source": [
    "# Demo: Conversation with auto-summarization\n",
    "chat = ConversationSummarizer(\n",
    "    \"You are a helpful coding assistant.\",\n",
    "    max_messages=6  # Low threshold for demo\n",
    ")\n",
    "\n",
    "questions = [\n",
    "    \"What's the best way to handle errors in Python?\",\n",
    "    \"Can you show me a try-except example?\",\n",
    "    \"What about custom exceptions?\",\n",
    "    \"How do I log errors properly?\",\n",
    "    \"What logging levels should I use?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nüë§ {q}\")\n",
    "    response = chat.chat(q)\n",
    "    print(f\"ü§ñ {response[:150]}...\")\n",
    "    print(f\"   Stats: {chat.stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hierarchical Summarization\n",
    "\n",
    "For very long documents: summarize chunks, then summarize summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, chunk_size: int = 2000) -> List[str]:\n",
    "    \"\"\"Split text into chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunks.append(' '.join(words[i:i + chunk_size]))\n",
    "    return chunks\n",
    "\n",
    "def hierarchical_summarize(text: str, focus: str = None) -> Dict:\n",
    "    \"\"\"Summarize long text hierarchically.\"\"\"\n",
    "    chunks = chunk_text(text)\n",
    "    \n",
    "    if len(chunks) == 1:\n",
    "        return {\"summary\": summarize_text(text, focus), \"chunks\": 1, \"levels\": 1}\n",
    "    \n",
    "    # Level 1: Summarize each chunk\n",
    "    chunk_summaries = [summarize_text(c, focus, max_tokens=300) for c in chunks]\n",
    "    print(f\"üìÑ Summarized {len(chunks)} chunks\")\n",
    "    \n",
    "    # Level 2: Combine summaries\n",
    "    combined = \"\\n\\n\".join([f\"Section {i+1}: {s}\" for i, s in enumerate(chunk_summaries)])\n",
    "    final = summarize_text(combined, focus, max_tokens=500)\n",
    "    \n",
    "    return {\n",
    "        \"summary\": final,\n",
    "        \"chunk_summaries\": chunk_summaries,\n",
    "        \"chunks\": len(chunks),\n",
    "        \"levels\": 2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Result: 1 chunks, 1 levels\n",
      "\n",
      "üìù Final Summary:\n",
      "## AWS Key Services Summary\n",
      "\n",
      "AWS offers a comprehensive cloud platform with core services across multiple categories:\n",
      "\n",
      "**Compute:** EC2 (virtual servers), Lambda (serverless functions)\n",
      "\n",
      "**Storage:** S3 (object storage), EBS (block storage), EFS (file systems)\n",
      "\n",
      "**Database:** RDS (relational), DynamoDB (NoSQL)\n",
      "\n",
      "**Networking:** VPC, Route 53 (DNS), CloudFront (CDN)\n",
      "\n",
      "**Security:** IAM (access management), KMS (encryption), WAF (web protection)\n",
      "\n",
      "**Machine Learning:** SageMaker (model training), Bedrock (foundation models)\n",
      "\n",
      "**Analytics:** Athena (queries), Redshift (data warehousing), Kinesis (streaming)\n",
      "\n",
      "**Developer Tools:** CodePipeline, CodeBuild, CodeDeploy (CI/CD)\n",
      "\n",
      "**Management:** CloudWatch (monitoring), CloudFormation (infrastructure as code)\n"
     ]
    }
   ],
   "source": [
    "# Demo with sample long text\n",
    "long_text = \"\"\"\n",
    "Amazon Web Services (AWS) provides a comprehensive cloud computing platform. \n",
    "The platform includes compute services like EC2 for virtual servers and Lambda for serverless functions.\n",
    "Storage options include S3 for object storage, EBS for block storage, and EFS for file systems.\n",
    "Database services range from RDS for relational databases to DynamoDB for NoSQL.\n",
    "Networking is handled through VPC, Route 53 for DNS, and CloudFront for CDN.\n",
    "Security features include IAM for access management, KMS for encryption, and WAF for web protection.\n",
    "Machine learning services include SageMaker for model training and Bedrock for foundation models.\n",
    "Analytics services include Athena for queries, Redshift for warehousing, and Kinesis for streaming.\n",
    "Developer tools include CodePipeline, CodeBuild, and CodeDeploy for CI/CD workflows.\n",
    "Management tools include CloudWatch for monitoring, CloudFormation for infrastructure as code.\n",
    "\"\"\" * 10  # Repeat to make it longer\n",
    "\n",
    "result = hierarchical_summarize(long_text, focus=\"key AWS services\")\n",
    "print(f\"\\nüìä Result: {result['chunks']} chunks, {result['levels']} levels\")\n",
    "print(f\"\\nüìù Final Summary:\\n{result['summary']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Context Manager\n",
    "\n",
    "Maintain structured context with selective summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredContextManager:\n",
    "    \"\"\"Manages context with separate sections that can be individually summarized.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sections = {\n",
    "            \"goals\": [],      # Never summarize - always keep full\n",
    "            \"facts\": [],      # Summarize when large\n",
    "            \"history\": [],    # Aggressively summarize\n",
    "            \"scratchpad\": []  # Temporary, can be cleared\n",
    "        }\n",
    "        self.summaries = {}\n",
    "        \n",
    "    def add(self, section: str, content: str):\n",
    "        \"\"\"Add content to a section.\"\"\"\n",
    "        if section in self.sections:\n",
    "            self.sections[section].append(content)\n",
    "            \n",
    "    def _summarize_section(self, section: str, threshold: int) -> str:\n",
    "        \"\"\"Summarize a section if it exceeds threshold.\"\"\"\n",
    "        content = \"\\n\".join(self.sections[section])\n",
    "        if len(content) > threshold:\n",
    "            summary = summarize_text(content, max_tokens=300)\n",
    "            self.summaries[section] = summary\n",
    "            self.sections[section] = []  # Clear after summarizing\n",
    "            return summary\n",
    "        return content\n",
    "    \n",
    "    def compile_context(self) -> str:\n",
    "        \"\"\"Compile all sections into final context string.\"\"\"\n",
    "        # Summarize sections that need it\n",
    "        self._summarize_section(\"facts\", threshold=2000)\n",
    "        self._summarize_section(\"history\", threshold=1000)\n",
    "        \n",
    "        parts = []\n",
    "        \n",
    "        # Goals: always full\n",
    "        if self.sections[\"goals\"]:\n",
    "            parts.append(f\"## Goals\\n\" + \"\\n\".join(self.sections[\"goals\"]))\n",
    "        \n",
    "        # Facts: use summary if available\n",
    "        facts = self.summaries.get(\"facts\") or \"\\n\".join(self.sections[\"facts\"])\n",
    "        if facts:\n",
    "            parts.append(f\"## Key Facts\\n{facts}\")\n",
    "        \n",
    "        # History: use summary if available\n",
    "        history = self.summaries.get(\"history\") or \"\\n\".join(self.sections[\"history\"])\n",
    "        if history:\n",
    "            parts.append(f\"## History Summary\\n{history}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(parts)\n",
    "    \n",
    "    def clear_scratchpad(self):\n",
    "        \"\"\"Clear temporary notes.\"\"\"\n",
    "        self.sections[\"scratchpad\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Compiled Context:\n",
      "## Goals\n",
      "Build a REST API for user management\n",
      "Use Python with FastAPI framework\n",
      "\n",
      "## Key Facts\n",
      "Database: PostgreSQL on RDS\n",
      "Auth: JWT tokens with 1-hour expiry\n",
      "Deployment: ECS Fargate\n",
      "\n",
      "## History Summary\n",
      "Created project structure\n",
      "Set up database models\n",
      "Implemented user CRUD endpoints\n",
      "Added authentication middleware\n"
     ]
    }
   ],
   "source": [
    "# Demo: Structured context\n",
    "ctx = StructuredContextManager()\n",
    "\n",
    "# Add goals (never summarized)\n",
    "ctx.add(\"goals\", \"Build a REST API for user management\")\n",
    "ctx.add(\"goals\", \"Use Python with FastAPI framework\")\n",
    "\n",
    "# Add facts (summarized when large)\n",
    "ctx.add(\"facts\", \"Database: PostgreSQL on RDS\")\n",
    "ctx.add(\"facts\", \"Auth: JWT tokens with 1-hour expiry\")\n",
    "ctx.add(\"facts\", \"Deployment: ECS Fargate\")\n",
    "\n",
    "# Add history (aggressively summarized)\n",
    "ctx.add(\"history\", \"Created project structure\")\n",
    "ctx.add(\"history\", \"Set up database models\")\n",
    "ctx.add(\"history\", \"Implemented user CRUD endpoints\")\n",
    "ctx.add(\"history\", \"Added authentication middleware\")\n",
    "\n",
    "print(\"üìã Compiled Context:\")\n",
    "print(ctx.compile_context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Progressive Summarization Agent\n",
    "\n",
    "An agent that progressively summarizes as it works through a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressiveSummarizationAgent:\n",
    "    \"\"\"Agent that maintains a running summary of its work.\"\"\"\n",
    "    \n",
    "    def __init__(self, task: str):\n",
    "        self.task = task\n",
    "        self.running_summary = f\"Task: {task}\"\n",
    "        self.step_count = 0\n",
    "        \n",
    "    def execute_step(self, step_description: str) -> str:\n",
    "        \"\"\"Execute a step and update running summary.\"\"\"\n",
    "        self.step_count += 1\n",
    "        \n",
    "        # Execute the step\n",
    "        response = bedrock.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"text\": \n",
    "                f\"Context:\\n{self.running_summary}\\n\\nExecute this step: {step_description}\"\n",
    "            }]}],\n",
    "            inferenceConfig={\"temperature\": 0.7, \"maxTokens\": 800}\n",
    "        )\n",
    "        result = response['output']['message']['content'][0]['text']\n",
    "        \n",
    "        # Update running summary (compress old + add new)\n",
    "        self._update_summary(step_description, result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _update_summary(self, step: str, result: str):\n",
    "        \"\"\"Update running summary with new step.\"\"\"\n",
    "        update_prompt = f\"\"\"Current summary:\n",
    "{self.running_summary}\n",
    "\n",
    "New step completed: {step}\n",
    "Result: {result[:500]}\n",
    "\n",
    "Create an updated summary that:\n",
    "1. Preserves the original task\n",
    "2. Keeps key decisions and findings\n",
    "3. Notes current progress\n",
    "4. Stays under 300 words\"\"\"\n",
    "        \n",
    "        response = bedrock.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"text\": update_prompt}]}],\n",
    "            inferenceConfig={\"temperature\": 0.3, \"maxTokens\": 400}\n",
    "        )\n",
    "        self.running_summary = response['output']['message']['content'][0]['text']\n",
    "        \n",
    "    def get_summary(self) -> str:\n",
    "        return f\"Steps completed: {self.step_count}\\n\\n{self.running_summary}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Step: Identify what data should be cached (products, user sessions, cart)\n",
      "‚úÖ Result: # Caching Strategy: Data Identification for E-commerce API\n",
      "\n",
      "## Primary Data Categories for Caching\n",
      "\n",
      "### 1. **Product Data** üõçÔ∏è\n",
      "**High Priority - Cache Aggressively**\n",
      "\n",
      "- **Product catalogs and listings...\n",
      "\n",
      "üîß Step: Choose caching technology (Redis vs Memcached)\n",
      "‚úÖ Result: # Technology Selection: Redis vs Memcached Analysis\n",
      "\n",
      "## Decision: **Redis Selected** ‚úÖ\n",
      "\n",
      "### Comprehensive Comparison Analysis\n",
      "\n",
      "| Feature | Redis | Memcached | E-commerce Requirement |\n",
      "|---------|-----...\n",
      "\n",
      "üîß Step: Define cache invalidation strategy\n",
      "‚úÖ Result: # Cache Invalidation Strategy Design\n",
      "\n",
      "## Cache Invalidation Patterns Implementation\n",
      "\n",
      "### 1. Time-Based Expiration (TTL) - Primary Strategy\n",
      "**Implementation across data types:**\n",
      "\n",
      "```redis\n",
      "# Product cat...\n",
      "\n",
      "üîß Step: Plan cache warming approach\n",
      "‚úÖ Result: # Cache Warming Strategy for E-commerce API\n",
      "\n",
      "## Cache Warming Approach ‚úÖ\n",
      "\n",
      "### 1. **Proactive Cache Warming Strategy**\n",
      "\n",
      "#### **A. Scheduled Warming (Primary Approach)**\n",
      "```\n",
      "Daily Schedule:\n",
      "‚îú‚îÄ‚îÄ 2:00 AM ...\n",
      "\n",
      "============================================================\n",
      "üìä FINAL SUMMARY\n",
      "============================================================\n",
      "Steps completed: 4\n",
      "\n",
      "# E-commerce API Caching Strategy Design\n",
      "\n",
      "## Task Overview\n",
      "Design a comprehensive caching strategy for an e-commerce API to optimize performance and reduce database load.\n",
      "\n",
      "## Progress: Data Identification, Technology Selection, Cache Invalidation & Cache Warming Complete ‚úÖ\n",
      "\n",
      "### Key Caching Categories Identified\n",
      "**1. Product Data (High Priority)**\n",
      "- Product catalogs/listings: TTL 1-4 hours\n",
      "- Product details/specifications: TTL 2-6 hours  \n",
      "- Product images/media URLs: TTL 24 hours\n",
      "\n",
      "**2. User Sessions & Shopping Cart Data**\n",
      "- Authentication tokens, user preferences, cart contents\n",
      "- Requires balance between performance and consistency\n",
      "\n",
      "### Technology Decision: Redis Selected ‚úÖ\n",
      "**Key advantages:** Complex data structures, persistence capabilities, clustering/replication, advanced features (pub/sub, transactions, Lua scripting) suited for e-commerce needs.\n",
      "\n",
      "### Cache Invalidation Strategy Established ‚úÖ\n",
      "**Multi-layered approach:**\n",
      "- **Time-based TTL**: Primary strategy with dynamic TTL based on product popularity\n",
      "- **Event-driven invalidation**: Real-time updates for inventory, pricing, product changes\n",
      "- **Manual invalidation**: Admin controls for immediate cache clearing\n",
      "- **Pattern-based invalidation**: Bulk operations using Redis key patterns\n",
      "\n",
      "### Cache Warming Strategy Implemented ‚úÖ\n",
      "**Proactive approach with scheduled warming:**\n",
      "- **Daily Schedule**: 2-6 AM warming cycles for core catalogs, popular products, categories, and trending searches\n",
      "- **Event-triggered warming**: New product launches, seasonal campaigns, flash sales\n",
      "- **Predictive warming**: ML-based prediction for trending products and user behavior patterns\n",
      "\n",
      "## Key Decisions Made\n",
      "- Prioritize product data for aggressive caching (high read-to-write ratio)\n"
     ]
    }
   ],
   "source": [
    "# Demo: Progressive summarization\n",
    "agent = ProgressiveSummarizationAgent(\"Design a caching strategy for an e-commerce API\")\n",
    "\n",
    "steps = [\n",
    "    \"Identify what data should be cached (products, user sessions, cart)\",\n",
    "    \"Choose caching technology (Redis vs Memcached)\",\n",
    "    \"Define cache invalidation strategy\",\n",
    "    \"Plan cache warming approach\"\n",
    "]\n",
    "\n",
    "for step in steps:\n",
    "    print(f\"\\nüîß Step: {step}\")\n",
    "    result = agent.execute_step(step)\n",
    "    print(f\"‚úÖ Result: {result[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(agent.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "‚úÖ **Summarize proactively** - Don't wait until context is full  \n",
    "‚úÖ **Preserve what matters** - Goals, decisions, key facts  \n",
    "‚úÖ **Use structure** - Different sections need different treatment  \n",
    "‚úÖ **Hierarchical approach** - For very long content, summarize in levels  \n",
    "‚úÖ **Running summaries** - Update as you go, not all at once  \n",
    "\n",
    "**When to use:**\n",
    "- Long conversations approaching context limits\n",
    "- Multi-step agent tasks\n",
    "- Processing large documents\n",
    "- When you notice quality degradation\n",
    "\n",
    "**References:**\n",
    "- [How to Fix Your Context](https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html)\n",
    "- [LangChain Context Engineering](https://github.com/langchain-ai/context_engineering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
