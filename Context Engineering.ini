Context Engineering
- 어떻게 모델에게 Context를 전달할 것인가
- https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html

1. RAG
- 'RAG is dead.'
- Context window의 사이즈가 커지면서 RAG의 무용론이 대두됨
- 하지만 Garbage in Garbage out, 불필요한 Context가 지나치게 많으면 오히려 더 큰 문제를 야기

2. Tool Loadout
- 불필요한 Tool Loading이 많으면 답변의 품질이 더 떨어짐
- Less is More. [https://arxiv.org/abs/2411.15399]

3. Context Quarantine (Context 격리)
- 불필요한 컨텍스트들이 없을 경우 더욱 정확한 답변
- 관심사의 분리
- Lead Agent와 Subtask Agent를 분리
- 다양한 Agent 간 Context를 Sharing하지 않도록 구성

4. Context Pruning
- 불필요한 컨텍스트 또는 정보를 제거
- 긴 컨텍스트가 LLM에 좋지 않은 영향을 줌
- Provence [https://arxiv.org/abs/2501.16214]

5. Context Summarization
- 요약된 내용을 Context로 전달
- Small Context Window 문제
- Context Distraction (산만함) [https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html#context-distraction]
- 내용을 요약하는 것은 쉬우나, 에이전트 작업에 맞게 수정하는 것은 매우 어려움. 
- 별도의 기능 또는 애플리케이션으로 이를 분리하고 최적화하는 것이 필요

6. Context Offloading
- 데이터를 LLM 외부에 저장해 두는 것 (tool이 사용할 수 있도록)
- Anthropic의 "think"[https://www.anthropic.com/engineering/claude-think-tool], 저자는 "scratchpad"와 같은 이름이면 더욱 적절할 것이라 생각
- 모델이 쓸 수 있는 일종의 "메모장", Context에 직접 사용되는 것은 아님
- Log Note, Progress Works.